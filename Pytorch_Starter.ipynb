{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import json\n",
    "from numpy.random import shuffle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os, sys\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23625, (23625, 300), 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('lookup.json') as fl:\n",
    "    tag_lookup = json.load(fl)\n",
    "    \n",
    "with open('word_list.txt') as fl:\n",
    "    vocab = fl.read().split('\\n')\n",
    "\n",
    "embeds = np.load('word_embeds.npy')\n",
    "wlookup = { word: index for index, word in enumerate(vocab) }\n",
    "\n",
    "len(vocab), embeds.shape, len(tag_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.376953125, 0.48046875)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(embeds[wlookup['Japan']]), np.max(embeds[wlookup['Russia']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14986, 3465, 3683)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('eng.train') as fl:\n",
    "    sents = fl.read().split('\\n\\n')[1:-1]\n",
    "    \n",
    "with open('eng.testa') as fl:\n",
    "    eval_sents = fl.read().split('\\n\\n')[1:-1]\n",
    "    \n",
    "with open('eng.testb') as fl:\n",
    "    test_sents = fl.read().split('\\n\\n')[1:-1]\n",
    "    \n",
    "len(sents), len(eval_sents), len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU NNP I-NP I-ORG\\nrejects VBZ I-VP O\\nGerman JJ I-NP I-MISC\\ncall NN I-NP O\\nto TO I-VP O\\nboycott VB I-VP O\\nBritish JJ I-NP I-MISC\\nlamb NN I-NP O\\n. . O O'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate the (embedded representation, 1-hot target predictions) for a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 300), (124, 9))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_sent(sent):\n",
    "    \n",
    "    words = sent.split('\\n')\n",
    "    inps = []\n",
    "    outs = []\n",
    "    for wordinfo in words:\n",
    "        word, _, _, tag = wordinfo.split()\n",
    "        try:\n",
    "            assert word in wlookup\n",
    "        except:\n",
    "            # word not in our known dictionary, so use the unk token\n",
    "            word = 'unk'\n",
    "        \n",
    "        inps.append(embeds[wlookup[word]])\n",
    "        hot = np.zeros(len(tag_lookup))\n",
    "        hot[tag_lookup[tag]] = 1\n",
    "        outs.append(hot)\n",
    "        \n",
    "    if(len(inps)<124):\n",
    "        for i in range(0,124-len(inps)):\n",
    "            inps.append(np.zeros(300))\n",
    "            hot = np.zeros(len(tag_lookup))\n",
    "            hot[tag_lookup[\"EMPTY\"]] = 1\n",
    "            outs.append(hot)\n",
    "    \n",
    "    return [np.vstack(inps), np.vstack(outs)]\n",
    "\n",
    "ins, outs = load_sent(sents[0])\n",
    "\n",
    "ins.shape, outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "124\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "def FindMax():\n",
    "    maxx=-1\n",
    "    for i in range(0,len(sents)):\n",
    "        ins, outs = load_sent(sents[i])\n",
    "        if(ins.shape[0]>maxx):\n",
    "            maxx=ins.shape[0]\n",
    "    print(maxx)\n",
    "    for i in range(0,len(eval_sents)):\n",
    "        ins, outs = load_sent(eval_sents[i])\n",
    "        if(ins.shape[0]>maxx):\n",
    "            maxx=ins.shape[0]\n",
    "    print(maxx)\n",
    "    for i in range(0,len(test_sents)):\n",
    "        ins, outs = load_sent(test_sents[i])\n",
    "        if(ins.shape[0]>maxx):\n",
    "            maxx=ins.shape[0]\n",
    "           \n",
    "    print(maxx)\n",
    "    \n",
    "    \n",
    "\n",
    "FindMax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5761, 3533, 4979, 2118, 1906, 14809, 2212, 12999, 8503, 1832]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSIZE = 32\n",
    "train_inds = list(range(len(sents)))\n",
    "shuffle(train_inds)\n",
    "train_inds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, insize=300, outsize=9, hsize=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Dropout\n",
    "        # TODO: nonlinearities\n",
    "        # TODO: Bidirectional\n",
    "\n",
    "        self.hsize = hsize\n",
    "        self.inp = nn.Sequential(\n",
    "            nn.Linear(insize, hsize),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hsize*2, outsize),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "        # FIXME: this is a uni-directional LSTM\n",
    "        self.rnn = nn.LSTM(hsize, hsize, 1, batch_first=True,bidirectional=True)\n",
    "        \n",
    "    def forward(self, inputs, hidden=None):\n",
    "        hin = self.inp(inputs)\n",
    "        \n",
    "        hout, hidden = self.rnn(hin)\n",
    "        \n",
    "        yout = self.out(hout)\n",
    "        \n",
    "        return yout, hidden\n",
    "    \n",
    "model = RNN().to(device)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "opt = optim.Adam(model.parameters(), lr=0.0005)\n",
    "# sch = optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: 0.0973\n",
      "[E1/1 - B14945/14986] Train: 0.0016 (elapsed: 670.21s)\n",
      "Eval: 0.0025\n"
     ]
    }
   ],
   "source": [
    "EPS = 1\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "n2t = lambda narr: torch.from_numpy(narr).to(device).float()\n",
    "\n",
    "def eval_model(evaldata, results=False):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    ypreds = []\n",
    "    for sent in evaldata:\n",
    "        Xs, Ys = zip(*[load_sent(sent)])\n",
    "        Xs, Ys = np.array(Xs), np.array(Ys)\n",
    "        \n",
    "        Xs, Ys = n2t(Xs), n2t(Ys)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            yhat, _ = model(Xs)\n",
    "            \n",
    "            ypreds.append(yhat)\n",
    "            loss = criterion(yhat, Ys)\n",
    "            losses.append(loss.item())\n",
    "    print('Eval: %.4f' % np.mean(losses))\n",
    "    \n",
    "    if results: \n",
    "        return ypreds\n",
    "    else:\n",
    "        return np.mean(losses)\n",
    "    \n",
    "eval_loss.append(eval_model(eval_sents))\n",
    "\n",
    "for epoch in range(EPS):\n",
    "    model.train()\n",
    "    t0 = time()\n",
    "    batch_loss = []\n",
    "    for bi in range(0, len(train_inds)-BSIZE, BSIZE):\n",
    "        inds = train_inds[bi:bi+BSIZE]\n",
    "\n",
    "        # TODO: correct formatting for batchsize >1\n",
    "        Xs, Ys = zip(*[load_sent(sents[ind]) for ind in inds])\n",
    "        Xs, Ys = np.array(Xs), np.array(Ys)\n",
    "        Xs, Ys = n2t(Xs), n2t(Ys)\n",
    "        # shape: (batch x seqlen x dim)\n",
    "        \n",
    "        yhat, _ = model(Xs)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = criterion(yhat, Ys)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        sys.stdout.write('\\r[E%d/%d - B%d/%d] Train: %.4f ' % (\n",
    "            epoch+1, EPS,\n",
    "            bi+1, len(train_inds),\n",
    "            loss.item(),\n",
    "        ))\n",
    "        batch_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(batch_loss))\n",
    "    sys.stdout.write('(elapsed: %.2fs)\\n' % (time() - t0))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    loss = eval_model(eval_sents)\n",
    "    eval_loss.append(loss)\n",
    "        \n",
    "    shuffle(train_inds)\n",
    "    # TODO: shuffle train inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0IAAADFCAYAAAB5A0KJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcAxS85on3LRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 3))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss[1:])\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: 0.0024\n"
     ]
    }
   ],
   "source": [
    "test_results = eval_model(test_sents, results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2tag = { index: tag for tag, index in tag_lookup.items() }\n",
    "with open('nn.output' , 'w') as fl:\n",
    "    assert len(test_results) == len(test_sents)\n",
    "    for ti, (yhat, schunk) in enumerate(zip(test_results, test_sents)):\n",
    "        yhat = yhat.detach().cpu().numpy()\n",
    "        for wi, wordinfo in enumerate(schunk.split('\\n')):\n",
    "            word, _, _, tag = wordinfo.split()\n",
    "            taghat = index2tag[np.argmax(yhat[0, wi, :])]\n",
    "\n",
    "            fl.write('%s %s %s\\n' % (word, taghat, tag))\n",
    "        fl.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46665 tokens with 4057 phrases; found: 5648 phrases; correct: 920.\r\n",
      "accuracy:  85.82%; precision:  16.29%; recall:  22.68%; FB1:  18.96\r\n",
      "                 : precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "              LOC: precision:  28.84%; recall:  66.34%; FB1:  40.20  1668\r\n",
      "             MISC: precision:   0.00%; recall:   0.00%; FB1:   0.00  702\r\n",
      "              ORG: precision:   0.54%; recall:  18.37%; FB1:   1.05  1661\r\n",
      "              PER: precision:  26.59%; recall:  13.14%; FB1:  17.59  1617\r\n"
     ]
    }
   ],
   "source": [
    "!python conlleval.py nn.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
